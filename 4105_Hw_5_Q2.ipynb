{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQRni4vj21PqiPxsus+fo1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pathin220/4105_ML_Hw5/blob/main/4105_Hw_5_Q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.a. Develop preprocessing and a training loop to train a linear regression model that predicts housing price based on the following input variables:\n",
        "#area, bedrooms, bathrooms, stories, parking\n",
        "\n",
        "#For this, you need to use the housing dataset. For training and validation, use 80% (training) and 20% (validation) split.\n",
        "# Identify the best parameters for your linear regression model based on the above input variables. In this case, you will have six parameters:\n",
        "\n",
        "#2.b Use 5000 epochs for your training. Explore different learning rates from 0.1 to 0.0001 (you need four separate trainings).\n",
        "# Report your loss and validation accuracy for every 500 epochs per training. Pick the best linear model.\n",
        "\n",
        "#2.c. Compare your results against the linear regression done in homework 1. Do you see meaningful differences?"
      ],
      "metadata": {
        "id": "nNliBTF-L-rQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "ay31g1l6MOL6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/My Drive/Machine Learning/Housing.csv'\n",
        "housing = pd.DataFrame(pd.read_csv(file_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnB_XUWeL_D_",
        "outputId": "cc42a6bd-994d-4479-f506-1884efc3aa41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mapping the variables to a binary output\n",
        "varlist_1 =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea', 'furnishingstatus']\n",
        "\n",
        "# Defining the map function\n",
        "def mapping(x):\n",
        "    return x.map({'yes': 1, 'no': 0, 'furnished':  1, 'semi-furnished':  0, 'unfurnished':  -1})\n",
        "\n",
        "housing[varlist_1] = housing[varlist_1].apply(mapping)\n"
      ],
      "metadata": {
        "id": "VcvbE3AhMBlI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the Dataset\n",
        "X_train, X_val = train_test_split(housing, train_size = 0.8, test_size = 0.2, random_state = 0)\n"
      ],
      "metadata": {
        "id": "lflNgeJhMS3k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting Variables\n",
        "Y_train = X_train.pop(\"price\")\n",
        "Y_val = X_val.pop(\"price\")"
      ],
      "metadata": {
        "id": "oKGOCEGAMUdQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardizing the Dataset\n",
        "standard = StandardScaler()\n",
        "vars = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
        "\n",
        "X_train_st = X_train\n",
        "X_train_st[vars] = standard.fit_transform(X_train_st[vars])\n",
        "\n",
        "X_val_st = X_val\n",
        "X_val_st[vars] = standard.fit_transform(X_val_st[vars])"
      ],
      "metadata": {
        "id": "7abjXlfWMV9z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the loss function\n",
        "def loss_fn(t_p, t_c):\n",
        "    squared_diffs = (t_p - t_c)**2\n",
        "    return squared_diffs.mean()"
      ],
      "metadata": {
        "id": "BXpAhhx5MXjS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model\n",
        "def model_h(t_u, w5, w4, w3, w2, w1, b):\n",
        "  return w5*t_u**5 + w4*t_u**4 + w3*t_u**3 + w2 * t_u ** 2 + w1 * t_u + b"
      ],
      "metadata": {
        "id": "vZv4ZbKNMY3e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)"
      ],
      "metadata": {
        "id": "cx-XLzs7Mac9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_st_numpy = np.c_[np.ones((len(Y_train), 1)), X_train_st[vars]]\n",
        "X_val_st_numpy = np.c_[np.ones((len(Y_val), 1)), X_val_st[vars]]"
      ],
      "metadata": {
        "id": "xEgbGE4_Mb2k"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_t = torch.tensor(X_train_st_numpy)\n",
        "X_val_t = torch.tensor(X_val_st_numpy)\n",
        "Y_train_t = torch.tensor(Y_train.values)\n",
        "Y_val_t = torch.tensor(Y_val.values)"
      ],
      "metadata": {
        "id": "6kQzlAebMdSb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_m = Y_train_t.float().mean()\n",
        "Y_train_st = Y_train.std()\n",
        "Y_train_st_t = (Y_train_t-Y_train_m) / Y_train_st"
      ],
      "metadata": {
        "id": "hvl-0da0MevD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining a training loop\n",
        "def training_loop(n_epochs, optimizer, params, t_u_train, t_c_train, t_u_val, t_c_val):\n",
        "  for epoch in range (1, n_epochs +1):\n",
        "\n",
        "    if params.grad is not None:\n",
        "       params.grad.zero_()\n",
        "\n",
        "    t_p_train = model_h(t_u_train, *params)\n",
        "    loss_train = loss_fn(t_p_train.transpose(0,1), t_c_train)\n",
        "\n",
        "    t_p_val = model_h(t_u_val, *params)\n",
        "    loss_val = loss_fn(t_p_val.transpose(0,1), t_c_val)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    if epoch <= 3 or epoch % 500 == 0:\n",
        "            print(f\"Epoch {epoch}, Training loss: {loss_train.item():.4f},\"\n",
        "                  f\" Validation loss: {loss_val.item():.4f}\\n\")\n",
        "  return params\n",
        "\n"
      ],
      "metadata": {
        "id": "1P_duKt9MgIb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SGD 1\n",
        "SGD_1_learning_rate = 1e-10\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer_SGD2 = optim.SGD([params], lr= SGD_1_learning_rate)\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer_SGD2,\n",
        "    params = params,\n",
        "    t_u_train = X_train_t,\n",
        "    t_c_train = Y_train_t,\n",
        "    t_u_val = X_val_t,\n",
        "    t_c_val = Y_val_t,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrNTfYFdMhXO",
        "outputId": "be6b5754-cf0d-4ab6-fd1a-a64011707b98"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 26469777039121.0156, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 2, Training loss: 26469775109834.8945, Validation loss: 25188976396646.2383\n",
            "\n",
            "Epoch 3, Training loss: 26469773180553.0859, Validation loss: 25188973784338.6445\n",
            "\n",
            "Epoch 500, Training loss: 26468815393815.4961, Validation loss: 25187676811293.6172\n",
            "\n",
            "Epoch 1000, Training loss: 26467853967709.3555, Validation loss: 25186374708878.4023\n",
            "\n",
            "Epoch 1500, Training loss: 26466894685737.6445, Validation loss: 25185075308681.8281\n",
            "\n",
            "Epoch 2000, Training loss: 26465937542263.7617, Validation loss: 25183778604007.8789\n",
            "\n",
            "Epoch 2500, Training loss: 26464982533492.0234, Validation loss: 25182484590249.2070\n",
            "\n",
            "Epoch 3000, Training loss: 26464029653790.8789, Validation loss: 25181193260458.2383\n",
            "\n",
            "Epoch 3500, Training loss: 26463078901346.4336, Validation loss: 25179904612739.5859\n",
            "\n",
            "Epoch 4000, Training loss: 26462130262689.1289, Validation loss: 25178618630664.7695\n",
            "\n",
            "Epoch 4500, Training loss: 26461183740208.0781, Validation loss: 25177335316884.2969\n",
            "\n",
            "Epoch 5000, Training loss: 26460239348036.9414, Validation loss: 25176054692565.1484\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([65.5474, 23.2831,  8.2987,  6.3373,  2.4985,  4.7773],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SGD 2\n",
        "SGD_2_learning_rate = 1e-15\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "SGD2_optimizer = optim.SGD([params], lr=SGD_2_learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = SGD2_optimizer,\n",
        "    params = params,\n",
        "    t_u_train = X_train_t,\n",
        "    t_c_train = Y_train_t,\n",
        "    t_u_val = X_val_t,\n",
        "    t_c_val = Y_val_t,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irZVU53yMix8",
        "outputId": "d2557f1e-8f50-4605-b836-c635018cfdfd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 26469777039121.0156, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 2, Training loss: 26469777039105.4453, Validation loss: 25188979008937.4609\n",
            "\n",
            "Epoch 3, Training loss: 26469777039089.8711, Validation loss: 25188979008916.1055\n",
            "\n",
            "Epoch 500, Training loss: 26469777031350.7656, Validation loss: 25188978998304.1562\n",
            "\n",
            "Epoch 1000, Training loss: 26469777023564.9492, Validation loss: 25188978987628.1445\n",
            "\n",
            "Epoch 1500, Training loss: 26469777015779.1289, Validation loss: 25188978976952.1328\n",
            "\n",
            "Epoch 2000, Training loss: 26469777007993.3125, Validation loss: 25188978966276.1289\n",
            "\n",
            "Epoch 2500, Training loss: 26469777000207.4883, Validation loss: 25188978955600.1211\n",
            "\n",
            "Epoch 3000, Training loss: 26469776992421.6758, Validation loss: 25188978944924.1094\n",
            "\n",
            "Epoch 3500, Training loss: 26469776984635.8516, Validation loss: 25188978934248.0977\n",
            "\n",
            "Epoch 4000, Training loss: 26469776976850.0234, Validation loss: 25188978923572.0781\n",
            "\n",
            "Epoch 4500, Training loss: 26469776969064.1953, Validation loss: 25188978912896.0625\n",
            "\n",
            "Epoch 5000, Training loss: 26469776961278.3711, Validation loss: 25188978902220.0469\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0006e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.7779e-05],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SGD 3\n",
        "SGD_3_learning_rate = 1e-20\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "SGD3_optimizer = optim.SGD([params], lr=SGD_3_learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = SGD3_optimizer,\n",
        "    params = params,\n",
        "    t_u_train = X_train_t,\n",
        "    t_c_train = Y_train_t,\n",
        "    t_u_val = X_val_t,\n",
        "    t_c_val = Y_val_t,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkDA6QAcMkZ7",
        "outputId": "a35c7385-79e6-4f6b-c4ef-af053b30b95d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 26469777039121.0156, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 2, Training loss: 26469777039121.0156, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 3, Training loss: 26469777039121.0156, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 500, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 1000, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 1500, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 2000, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 2500, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 3000, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 3500, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 4000, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 4500, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 5000, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.7778e-10],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SGD 4\n",
        "SGD_4_learning_rate = 1e-25\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "SGD4_optimizer = optim.SGD([params], lr=SGD_3_learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = SGD4_optimizer,\n",
        "    params = params,\n",
        "    t_u_train = X_train_t,\n",
        "    t_c_train = Y_train_t,\n",
        "    t_u_val = X_val_t,\n",
        "    t_c_val = Y_val_t,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTKxGpMdMmE0",
        "outputId": "c37eb453-573e-4e27-fa2b-380efd271f96"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 26469777039121.0156, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 2, Training loss: 26469777039121.0156, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 3, Training loss: 26469777039121.0156, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 500, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 1000, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 1500, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 2000, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 2500, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 3000, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 3500, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 4000, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 4500, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n",
            "Epoch 5000, Training loss: 26469777039121.0117, Validation loss: 25188979008958.8086\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.7778e-10],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adam Number 1\n",
        "Adam_1_learning_rate = 0.01\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "Adam_1_optimizer = optim.Adam([params], lr= Adam_1_learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = Adam_1_optimizer,\n",
        "    params = params,\n",
        "    t_u_train = X_train_t,\n",
        "    t_c_train = Y_train_t,\n",
        "    t_u_val = X_val_t,\n",
        "    t_c_val = Y_val_t,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyXduYrFMn6H",
        "outputId": "9b99d785-4ab5-4061-f19f-ead7eb06ba6b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 26469777039121.0156, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 2, Training loss: 26469774914470.9961, Validation loss: 25188976267024.0977\n",
            "\n",
            "Epoch 3, Training loss: 26469772789824.5859, Validation loss: 25188973525093.5547\n",
            "\n",
            "Epoch 500, Training loss: 26468717483495.9102, Validation loss: 25187611564161.8594\n",
            "\n",
            "Epoch 1000, Training loss: 26467657080150.0430, Validation loss: 25186242921438.7539\n",
            "\n",
            "Epoch 1500, Training loss: 26466597886775.9375, Validation loss: 25184875733593.0977\n",
            "\n",
            "Epoch 2000, Training loss: 26465539839935.3828, Validation loss: 25183509916952.3750\n",
            "\n",
            "Epoch 2500, Training loss: 26464482870531.8906, Validation loss: 25182145377690.6133\n",
            "\n",
            "Epoch 3000, Training loss: 26463426935187.1445, Validation loss: 25180782055690.1562\n",
            "\n",
            "Epoch 3500, Training loss: 26462372027662.0078, Validation loss: 25179419942843.3633\n",
            "\n",
            "Epoch 4000, Training loss: 26461318173104.6211, Validation loss: 25178059078026.6914\n",
            "\n",
            "Epoch 4500, Training loss: 26460265217308.8008, Validation loss: 25176699251527.0469\n",
            "\n",
            "Epoch 5000, Training loss: 26459213160274.5547, Validation loss: 25175340463344.4141\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([50.9264, 50.9527, 50.9667, 50.9916, 50.9918, 49.9974],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adam Number 2\n",
        "Adam_2_learning_rate = 0.01\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "Adam_2_optimizer = optim.Adam([params], lr= Adam_2_learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = Adam_2_optimizer,\n",
        "    params = params,\n",
        "    t_u_train = X_train_t,\n",
        "    t_c_train = Y_train_t,\n",
        "    t_u_val = X_val_t,\n",
        "    t_c_val = Y_val_t,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tXDn5zjPWFG",
        "outputId": "52b9af2d-85c9-457f-84ba-7357629fe320"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 26469777039121.0156, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 2, Training loss: 26469774914470.9961, Validation loss: 25188976267024.0977\n",
            "\n",
            "Epoch 3, Training loss: 26469772789824.5859, Validation loss: 25188973525093.5547\n",
            "\n",
            "Epoch 500, Training loss: 26468717483495.9102, Validation loss: 25187611564161.8594\n",
            "\n",
            "Epoch 1000, Training loss: 26467657080150.0430, Validation loss: 25186242921438.7539\n",
            "\n",
            "Epoch 1500, Training loss: 26466597886775.9375, Validation loss: 25184875733593.0977\n",
            "\n",
            "Epoch 2000, Training loss: 26465539839935.3828, Validation loss: 25183509916952.3750\n",
            "\n",
            "Epoch 2500, Training loss: 26464482870531.8906, Validation loss: 25182145377690.6133\n",
            "\n",
            "Epoch 3000, Training loss: 26463426935187.1445, Validation loss: 25180782055690.1562\n",
            "\n",
            "Epoch 3500, Training loss: 26462372027662.0078, Validation loss: 25179419942843.3633\n",
            "\n",
            "Epoch 4000, Training loss: 26461318173104.6211, Validation loss: 25178059078026.6914\n",
            "\n",
            "Epoch 4500, Training loss: 26460265217308.8008, Validation loss: 25176699251527.0469\n",
            "\n",
            "Epoch 5000, Training loss: 26459213160274.5547, Validation loss: 25175340463344.4141\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([50.9264, 50.9527, 50.9667, 50.9916, 50.9918, 49.9974],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Adam_3_learning_rate = 0.001\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "Adam_3_optimizer = optim.Adam([params], lr= Adam_3_learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = Adam_3_optimizer,\n",
        "    params = params,\n",
        "    t_u_train = X_train_t,\n",
        "    t_c_train = Y_train_t,\n",
        "    t_u_val = X_val_t,\n",
        "    t_c_val = Y_val_t,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og_tg1oKQL7p",
        "outputId": "7028dd5a-13b0-4d14-9064-65076a2ab124"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 26469777039121.0156, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 2, Training loss: 26469776826646.1758, Validation loss: 25188978734752.5273\n",
            "\n",
            "Epoch 3, Training loss: 26469776614171.3711, Validation loss: 25188978460546.2891\n",
            "\n",
            "Epoch 500, Training loss: 26469671026314.9180, Validation loss: 25188842195410.2383\n",
            "\n",
            "Epoch 1000, Training loss: 26469564814189.8945, Validation loss: 25188705123342.7305\n",
            "\n",
            "Epoch 1500, Training loss: 26469458611165.6055, Validation loss: 25188568061782.4102\n",
            "\n",
            "Epoch 2000, Training loss: 26469352417160.8398, Validation loss: 25188431010642.2305\n",
            "\n",
            "Epoch 2500, Training loss: 26469246232744.5430, Validation loss: 25188293970484.6719\n",
            "\n",
            "Epoch 3000, Training loss: 26469140057349.4805, Validation loss: 25188156940748.9414\n",
            "\n",
            "Epoch 3500, Training loss: 26469033890974.7227, Validation loss: 25188019921434.4727\n",
            "\n",
            "Epoch 4000, Training loss: 26468927733619.8242, Validation loss: 25187882912540.1523\n",
            "\n",
            "Epoch 4500, Training loss: 26468821585282.7266, Validation loss: 25187745914064.2852\n",
            "\n",
            "Epoch 5000, Training loss: 26468715445967.9961, Validation loss: 25187608926011.3711\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.9997, 5.9997, 5.9997, 5.9997, 5.9997, 4.9998], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Adam_4_learning_rate = 0.0001\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "Adam_4_optimizer = optim.Adam([params], lr= Adam_4_learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = Adam_4_optimizer,\n",
        "    params = params,\n",
        "    t_u_train = X_train_t,\n",
        "    t_c_train = Y_train_t,\n",
        "    t_u_val = X_val_t,\n",
        "    t_c_val = Y_val_t,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGa_HW7CQff1",
        "outputId": "e58c99de-2b3f-4825-97f9-750dbbc9ecea"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 26469777039121.0156, Validation loss: 25188979008958.8125\n",
            "\n",
            "Epoch 2, Training loss: 26469777017871.1055, Validation loss: 25188978981535.0273\n",
            "\n",
            "Epoch 3, Training loss: 26469776996621.2070, Validation loss: 25188978954111.2422\n",
            "\n",
            "Epoch 500, Training loss: 26469766435460.9844, Validation loss: 25188965324538.7695\n",
            "\n",
            "Epoch 1000, Training loss: 26469755810635.7891, Validation loss: 25188951612793.7656\n",
            "\n",
            "Epoch 1500, Training loss: 26469745185900.9180, Validation loss: 25188937901153.0820\n",
            "\n",
            "Epoch 2000, Training loss: 26469734561256.2148, Validation loss: 25188924189616.5938\n",
            "\n",
            "Epoch 2500, Training loss: 26469723936701.7539, Validation loss: 25188910478184.3555\n",
            "\n",
            "Epoch 3000, Training loss: 26469713312308.7266, Validation loss: 25188896766926.7539\n",
            "\n",
            "Epoch 3500, Training loss: 26469702688005.9492, Validation loss: 25188883055773.4102\n",
            "\n",
            "Epoch 4000, Training loss: 26469692063793.4141, Validation loss: 25188869344724.3242\n",
            "\n",
            "Epoch 4500, Training loss: 26469681439671.1211, Validation loss: 25188855633779.4922\n",
            "\n",
            "Epoch 5000, Training loss: 26469670815639.0781, Validation loss: 25188841922938.9180\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.5001, 1.5001, 1.5001, 1.5001, 1.5001, 0.5000], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}